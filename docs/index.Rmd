---
title: "Data Preprocessing : Comparing Oversampling and Undersampling Algorithms for Class Imbalance Treatment"
author: "John Pauline Pineda"
date: "April 30, 2023"
output: 
  html_document:
    toc: true
    toc_depth: 3
    theme: readable
    highlight: tango
    css: doc.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=15, fig.height=10)
```

# **1. Table of Contents**
|
| This project explores different oversampling and undersampling methods to address imbalanced classification problems using various helpful packages in <mark style="background-color: #CCECFF">**R**</mark>. The algorithms applied to augment imbalanced data prior to model training by updating the original data set to minimize the effect of the disproportionate ratio of instances in each class included **Near Miss**, **Tomek Links**, **Adaptive Synthetic Algorithm**, **Borderline Synthetic Minority Oversampling Technique**, **Synthetic Minority Oversampling Technique** and **Random Oversampling Examples**. The derived class distributions were compared to the original data set and those applied with both random undersampling and oversampling methods. Using the Logistic Regression model structure, the corresponding logistic curves estimated from both the original and updated data were subjectively assessed in terms of skewness, data sparsity and class overlap. Considering the differences in their intended applications dependent on the quality and characteristics of the data being evaluated, a comparison of each methodâ€™s strengths and limitations was briefly discussed.
|
| Oversampling and undersampling algorithms address imbalanced classification problems by augmenting the data set used for model training based on its inherent characteristics to achieve a more reasonably balanced distribution between the majority and minority classes. In oversampling, new instances are created from the minor class instead of merely creating copies, by selecting two or more similar instances (using a distance measure) and perturbing an instance one attribute at a time by a random amount within the difference to the neighboring instances. In undersampling, a subset of instances from the majority class is removed based on relationships between nearest neighbors by having the minimum distance in the feature space with other instances belonging to the minority classes. The algorithms applied in this study (mostly contained in the <mark style="background-color: #CCECFF">**caret**</mark>, <mark style="background-color: #CCECFF">**themis**</mark> and <mark style="background-color: #CCECFF">**ROSE**</mark> packages attempt to augment imbalanced data prior to model training by updating the original data set to minimize the effect of the disproportionate ratio of instances in each class.
|
##  1.1 Sample Data
|
| The <mark style="background-color: #EEEEEE;color: #FF0000">**Sonar**</mark>  dataset from the  <mark style="background-color: #CCECFF">**mlbench**</mark> package was used for this illustrated example. The original dataset was transformed to simulate class imbalance. Only a pair of predictors was explored in the study to facilitate a clearer visualization of the class distribution.
|
| Preliminary dataset assessment:
|
| **[A]** 136 rows (observations)
|      **[A.1]** Train Set = 136 observations with class ratio of 80:20
| 
| **[B]** 3 columns (variables)
|      **[B.1]** 1/3 response = <span style="color: #FF0000">Class</span> variable (factor)
|             **[B.1.1]** Levels = <span style="color: #FF0000">Class=R</span> < <span style="color: #FF0000">Class=M</span>
|      **[B.2]** 2/3 predictors = All remaining variables (2/2 numeric)
|     
| 

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.1, warning=FALSE, message=FALSE}
##################################
# Loading R libraries
##################################
library(AppliedPredictiveModeling)
library(caret)
library(rpart)
library(lattice)
library(dplyr)
library(tidyr)
library(moments)
library(skimr)
library(RANN)
library(mlbench)
library(pls)
library(corrplot)
library(lares)
library(DMwR)
library(gridExtra)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(stats)
library(nnet)
library(elasticnet)
library(earth)
library(party)
library(kernlab)
library(randomForest)
library(Cubist)
library(pROC)
library(ggpubr)
library(mda)
library(klaR)
library(pamr)
library(themis)
library(ROSE)

##################################
# Loading source and
# formulating the train set
##################################
data(Sonar)

Sonar.Original <- Sonar

Sonar.M <- Sonar[Sonar$Class=="M",]
Sonar.R <- Sonar[Sonar$Class=="R",]
set.seed(12345678)
Sonar.R.Reduced <- Sonar.R[sample(1:nrow(Sonar.R),25),]

Sonar <- as.data.frame(rbind(Sonar.M,Sonar.R.Reduced))
Sonar$Class <- factor(Sonar$Class,
                         levels=c("M","R"))

Sonar_Train <- Sonar[,c("Class","V1","V11")]

##################################
# Performing a general exploration of the train set
##################################
dim(Sonar_Train)
str(Sonar_Train)
summary(Sonar_Train)

##################################
# Formulating a data type assessment summary
##################################
PDA <- Sonar_Train
(PDA.Summary <- data.frame(
  Column.Index=c(1:length(names(PDA))),
  Column.Name= names(PDA), 
  Column.Type=sapply(PDA, function(x) class(x)), 
  row.names=NULL)
)
```

</details>

##  1.2 Data Quality Assessment
|
| Data quality assessment:
|
| **[A]** No missing observations noted for any variable.
|
| **[B]** No low variance noted with First.Second.Mode.Ratio>5.
|
| **[C]** No low variance noted for any variable with Unique.Count.Ratio<0.01.
|
| **[D]** No high skewness noted for any variable with Skewness>3 or Skewness<(-3).
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.2, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DQA <- Sonar_Train

##################################
# Formulating an overall data quality assessment summary
##################################
(DQA.Summary <- data.frame(
  Column.Index=c(1:length(names(DQA))),
  Column.Name= names(DQA), 
  Column.Type=sapply(DQA, function(x) class(x)), 
  Row.Count=sapply(DQA, function(x) nrow(DQA)),
  NA.Count=sapply(DQA,function(x)sum(is.na(x))),
  Fill.Rate=sapply(DQA,function(x)format(round((sum(!is.na(x))/nrow(DQA)),3),nsmall=3)),
  row.names=NULL)
)

##################################
# Listing all predictors
##################################
DQA.Predictors <- DQA[,!names(DQA) %in% c("Class")]

##################################
# Listing all numeric predictors
##################################
DQA.Predictors.Numeric <- DQA.Predictors[,sapply(DQA.Predictors, is.numeric)]

if (length(names(DQA.Predictors.Numeric))>0) {
    print(paste0("There are ",
               (length(names(DQA.Predictors.Numeric))),
               " numeric predictor variable(s)."))
} else {
  print("There are no numeric predictor variables.")
}

##################################
# Listing all factor predictors
##################################
DQA.Predictors.Factor <- DQA.Predictors[,sapply(DQA.Predictors, is.factor)]

if (length(names(DQA.Predictors.Factor))>0) {
    print(paste0("There are ",
               (length(names(DQA.Predictors.Factor))),
               " factor predictor variable(s)."))
} else {
  print("There are no factor predictor variables.")
}

##################################
# Formulating a data quality assessment summary for factor predictors
##################################
if (length(names(DQA.Predictors.Factor))>0) {
  
  ##################################
  # Formulating a function to determine the first mode
  ##################################
  FirstModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
  }

  ##################################
  # Formulating a function to determine the second mode
  ##################################
  SecondModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    fm = ux[tab == max(tab)]
    sm = x[!(x %in% fm)]
    usm <- unique(sm)
    tabsm <- tabulate(match(sm, usm))
    ifelse(is.na(usm[tabsm == max(tabsm)])==TRUE,
           return("x"),
           return(usm[tabsm == max(tabsm)]))
  }
  
  (DQA.Predictors.Factor.Summary <- data.frame(
  Column.Name= names(DQA.Predictors.Factor), 
  Column.Type=sapply(DQA.Predictors.Factor, function(x) class(x)), 
  Unique.Count=sapply(DQA.Predictors.Factor, function(x) length(unique(x))),
  First.Mode.Value=sapply(DQA.Predictors.Factor, function(x) as.character(FirstModes(x)[1])),
  Second.Mode.Value=sapply(DQA.Predictors.Factor, function(x) as.character(SecondModes(x)[1])),
  First.Mode.Count=sapply(DQA.Predictors.Factor, function(x) sum(na.omit(x) == FirstModes(x)[1])),
  Second.Mode.Count=sapply(DQA.Predictors.Factor, function(x) sum(na.omit(x) == SecondModes(x)[1])),
  Unique.Count.Ratio=sapply(DQA.Predictors.Factor, function(x) format(round((length(unique(x))/nrow(DQA.Predictors.Factor)),3), nsmall=3)),
  First.Second.Mode.Ratio=sapply(DQA.Predictors.Factor, function(x) format(round((sum(na.omit(x) == FirstModes(x)[1])/sum(na.omit(x) == SecondModes(x)[1])),3), nsmall=3)),
  row.names=NULL)
  )
  
} 

##################################
# Formulating a data quality assessment summary for numeric predictors
##################################
if (length(names(DQA.Predictors.Numeric))>0) {
  
  ##################################
  # Formulating a function to determine the first mode
  ##################################
  FirstModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
  }

  ##################################
  # Formulating a function to determine the second mode
  ##################################
  SecondModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    fm = ux[tab == max(tab)]
    sm = na.omit(x)[!(na.omit(x) %in% fm)]
    usm <- unique(sm)
    tabsm <- tabulate(match(sm, usm))
    ifelse(is.na(usm[tabsm == max(tabsm)])==TRUE,
           return(0.00001),
           return(usm[tabsm == max(tabsm)]))
  }
  
  (DQA.Predictors.Numeric.Summary <- data.frame(
  Column.Name= names(DQA.Predictors.Numeric), 
  Column.Type=sapply(DQA.Predictors.Numeric, function(x) class(x)), 
  Unique.Count=sapply(DQA.Predictors.Numeric, function(x) length(unique(x))),
  Unique.Count.Ratio=sapply(DQA.Predictors.Numeric, function(x) format(round((length(unique(x))/nrow(DQA.Predictors.Numeric)),3), nsmall=3)),
  First.Mode.Value=sapply(DQA.Predictors.Numeric, function(x) format(round((FirstModes(x)[1]),3),nsmall=3)),
  Second.Mode.Value=sapply(DQA.Predictors.Numeric, function(x) format(round((SecondModes(x)[1]),3),nsmall=3)),
  First.Mode.Count=sapply(DQA.Predictors.Numeric, function(x) sum(na.omit(x) == FirstModes(x)[1])),
  Second.Mode.Count=sapply(DQA.Predictors.Numeric, function(x) sum(na.omit(x) == SecondModes(x)[1])),
  First.Second.Mode.Ratio=sapply(DQA.Predictors.Numeric, function(x) format(round((sum(na.omit(x) == FirstModes(x)[1])/sum(na.omit(x) == SecondModes(x)[1])),3), nsmall=3)),
  Minimum=sapply(DQA.Predictors.Numeric, function(x) format(round(min(x,na.rm = TRUE),3), nsmall=3)),
  Mean=sapply(DQA.Predictors.Numeric, function(x) format(round(mean(x,na.rm = TRUE),3), nsmall=3)),
  Median=sapply(DQA.Predictors.Numeric, function(x) format(round(median(x,na.rm = TRUE),3), nsmall=3)),
  Maximum=sapply(DQA.Predictors.Numeric, function(x) format(round(max(x,na.rm = TRUE),3), nsmall=3)),
  Skewness=sapply(DQA.Predictors.Numeric, function(x) format(round(skewness(x,na.rm = TRUE),3), nsmall=3)),
  Kurtosis=sapply(DQA.Predictors.Numeric, function(x) format(round(kurtosis(x,na.rm = TRUE),3), nsmall=3)),
  Percentile25th=sapply(DQA.Predictors.Numeric, function(x) format(round(quantile(x,probs=0.25,na.rm = TRUE),3), nsmall=3)),
  Percentile75th=sapply(DQA.Predictors.Numeric, function(x) format(round(quantile(x,probs=0.75,na.rm = TRUE),3), nsmall=3)),
  row.names=NULL)
  )  
  
}

##################################
# Identifying potential data quality issues
##################################

##################################
# Checking for missing observations
##################################
if ((nrow(DQA.Summary[DQA.Summary$NA.Count>0,]))>0){
  print(paste0("Missing observations noted for ",
               (nrow(DQA.Summary[DQA.Summary$NA.Count>0,])),
               " variable(s) with NA.Count>0 and Fill.Rate<1.0."))
  DQA.Summary[DQA.Summary$NA.Count>0,]
} else {
  print("No missing observations noted.")
}

##################################
# Checking for zero or near-zero variance predictors
##################################
if (length(names(DQA.Predictors.Factor))==0) {
  print("No factor predictors noted.")
} else if (nrow(DQA.Predictors.Factor.Summary[as.numeric(as.character(DQA.Predictors.Factor.Summary$First.Second.Mode.Ratio))>5,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Predictors.Factor.Summary[as.numeric(as.character(DQA.Predictors.Factor.Summary$First.Second.Mode.Ratio))>5,])),
               " factor variable(s) with First.Second.Mode.Ratio>5."))
  DQA.Predictors.Factor.Summary[as.numeric(as.character(DQA.Predictors.Factor.Summary$First.Second.Mode.Ratio))>5,]
} else {
  print("No low variance factor predictors due to high first-second mode ratio noted.")
}

if (length(names(DQA.Predictors.Numeric))==0) {
  print("No numeric predictors noted.")
} else if (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$First.Second.Mode.Ratio))>5,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$First.Second.Mode.Ratio))>5,])),
               " numeric variable(s) with First.Second.Mode.Ratio>5."))
  DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$First.Second.Mode.Ratio))>5,]
} else {
  print("No low variance numeric predictors due to high first-second mode ratio noted.")
}

if (length(names(DQA.Predictors.Numeric))==0) {
  print("No numeric predictors noted.")
} else if (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Unique.Count.Ratio))<0.01,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Unique.Count.Ratio))<0.01,])),
               " numeric variable(s) with Unique.Count.Ratio<0.01."))
  DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Unique.Count.Ratio))<0.01,]
} else {
  print("No low variance numeric predictors due to low unique count ratio noted.")
}

##################################
# Checking for skewed predictors
##################################
if (length(names(DQA.Predictors.Numeric))==0) {
  print("No numeric predictors noted.")
} else if (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))>3 |
                                               as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))<(-3),])>0){
  print(paste0("High skewness observed for ",
  (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))>3 |
                                               as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))<(-3),])),
  " numeric variable(s) with Skewness>3 or Skewness<(-3)."))
  DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))>3 |
                                 as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))<(-3),]
} else {
  print("No skewed numeric predictors noted.")
}

```

</details>

##  1.3 Data Preprocessing

###  1.3.1 Outlier
|
| Outlier data assessment:
|
| **[A]** Outliers noted for 2 variables  with the numeric data visualized through a boxplot including observations classified as suspected outliers using the IQR criterion. The IQR criterion means that all observations above the (75th percentile + 1.5 x IQR) or below the (25th percentile - 1.5 x IQR) are suspected outliers, where IQR is the difference between the third quartile (75th percentile) and first quartile (25th percentile). Outlier treatment for numerical stability remains optional depending on potential model requirements for the subsequent steps.
|      **[A.1]** <span style="color: #FF0000">V1</span> variable (8 outliers detected)
|      **[A.2]** <span style="color: #FF0000">V11</span> variable (5 outliers detected)
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.1, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- Sonar_Train

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("Class")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,sapply(DPA.Predictors, is.numeric)]

##################################
# Identifying outliers for the numeric predictors
##################################
OutlierCountList <- c()

for (i in 1:ncol(DPA.Predictors.Numeric)) {
  Outliers <- boxplot.stats(DPA.Predictors.Numeric[,i])$out
  OutlierCount <- length(Outliers)
  OutlierCountList <- append(OutlierCountList,OutlierCount)
  OutlierIndices <- which(DPA.Predictors.Numeric[,i] %in% c(Outliers))
  boxplot(DPA.Predictors.Numeric[,i], 
          ylab = names(DPA.Predictors.Numeric)[i], 
          main = names(DPA.Predictors.Numeric)[i],
          horizontal=TRUE)
  mtext(paste0(OutlierCount, " Outlier(s) Detected"))
}

OutlierCountSummary <- as.data.frame(cbind(names(DPA.Predictors.Numeric),(OutlierCountList)))
names(OutlierCountSummary) <- c("NumericPredictors","OutlierCount")
OutlierCountSummary$OutlierCount <- as.numeric(as.character(OutlierCountSummary$OutlierCount))
NumericPredictorWithOutlierCount <- nrow(OutlierCountSummary[OutlierCountSummary$OutlierCount>0,])
print(paste0(NumericPredictorWithOutlierCount, " numeric variable(s) were noted with outlier(s)." ))

##################################
# Gathering descriptive statistics
##################################
(DPA_Skimmed <- skim(DPA.Predictors.Numeric))

###################################
# Verifying the data dimensions
###################################
dim(DPA.Predictors.Numeric)

```

</details>

###  1.3.2 Zero and Near-Zero Variance
|
| Zero and near-zero variance data assessment:
|
| **[A]** No low variance noted for any variable from the previous data quality assessment using a lower threshold.
|
| **[B]** No low variance noted for any variables using a preprocessing summary from the <mark style="background-color: #CCECFF">**caret**</mark> package. The <span style="color: #0000FF">nearZeroVar</span> method using both the <span style="color: #0000FF">freqCut</span> and <span style="color: #0000FF">uniqueCut</span> criteria set at 95/5 and 10, respectively, were applied on the dataset.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.2, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- Sonar_Train

##################################
# Gathering descriptive statistics
##################################
(DPA_Skimmed <- skim(DPA))

##################################
# Identifying columns with low variance
###################################
DPA_LowVariance <- nearZeroVar(DPA,
                               freqCut = 95/5,
                               uniqueCut = 10,
                               saveMetrics= TRUE)
(DPA_LowVariance[DPA_LowVariance$nzv,])

if ((nrow(DPA_LowVariance[DPA_LowVariance$nzv,]))==0){

  print("No low variance predictors noted.")

} else {

  print(paste0("Low variance observed for ",
               (nrow(DPA_LowVariance[DPA_LowVariance$nzv,])),
               " numeric variable(s) with First.Second.Mode.Ratio>4 and Unique.Count.Ratio<0.10."))

  DPA_LowVarianceForRemoval <- (nrow(DPA_LowVariance[DPA_LowVariance$nzv,]))

  print(paste0("Low variance can be resolved by removing ",
               (nrow(DPA_LowVariance[DPA_LowVariance$nzv,])),
               " numeric variable(s)."))

  for (j in 1:DPA_LowVarianceForRemoval) {
  DPA_LowVarianceRemovedVariable <- rownames(DPA_LowVariance[DPA_LowVariance$nzv,])[j]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_LowVarianceRemovedVariable))
  }

  DPA %>%
  skim() %>%
  dplyr::filter(skim_variable %in% rownames(DPA_LowVariance[DPA_LowVariance$nzv,]))

  ##################################
  # Filtering out columns with low variance
  #################################
  DPA_ExcludedLowVariance <- DPA[,!names(DPA) %in% rownames(DPA_LowVariance[DPA_LowVariance$nzv,])]

  ##################################
  # Gathering descriptive statistics
  ##################################
  (DPA_ExcludedLowVariance_Skimmed <- skim(DPA_ExcludedLowVariance))
  
  ###################################
  # Verifying the data dimensions
  ###################################
  dim(DPA_ExcludedLowVariance)
  
} 

```

</details>

###  1.3.3 Collinearity
|
| High collinearity data assessment:
|
| **[A]** No high correlation > 95% were noted for any variable as confirmed using the preprocessing summaries from the <mark style="background-color: #CCECFF">**caret**</mark> and <mark style="background-color: #CCECFF">**lares**</mark> packages.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.3, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- Sonar_Train

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("Class")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,sapply(DPA.Predictors, is.numeric)]

##################################
# Visualizing pairwise correlation between predictors
##################################
DPA_CorrelationTest <- cor.mtest(DPA.Predictors.Numeric,
                       method = "pearson",
                       conf.level = .95)

corrplot(cor(DPA.Predictors.Numeric,
             method = "pearson",
             use="pairwise.complete.obs"), 
         method = "circle",
         type = "upper", 
         order = "original", 
         tl.col = "black", 
         tl.cex = 0.75,
         tl.srt = 90, 
         sig.level = 0.05, 
         p.mat = DPA_CorrelationTest$p,
         insig = "blank")



##################################
# Identifying the highly correlated variables
##################################
DPA_Correlation <-  cor(DPA.Predictors.Numeric, 
                        method = "pearson",
                        use="pairwise.complete.obs")
(DPA_HighlyCorrelatedCount <- sum(abs(DPA_Correlation[upper.tri(DPA_Correlation)]) > 0.95))

if (DPA_HighlyCorrelatedCount == 0) {
  
  print("No highly correlated predictors noted.")
  
} else {
  print(paste0("High correlation observed for ",
               (DPA_HighlyCorrelatedCount),
               " pairs of numeric variable(s) with Correlation.Coefficient>0.95."))

  (DPA_HighlyCorrelatedPairs <- corr_cross(DPA.Predictors.Numeric,
  max_pvalue = 0.05,
  top = DPA_HighlyCorrelatedCount,
  rm.na = TRUE,
  grid = FALSE
))

}


if (DPA_HighlyCorrelatedCount > 0) {
  DPA_HighlyCorrelated <- findCorrelation(DPA_Correlation, cutoff = 0.95)

  (DPA_HighlyCorrelatedForRemoval <- length(DPA_HighlyCorrelated))

  print(paste0("High correlation can be resolved by removing ",
               (DPA_HighlyCorrelatedForRemoval),
               " numeric variable(s)."))

  for (j in 1:DPA_HighlyCorrelatedForRemoval) {
  DPA_HighlyCorrelatedRemovedVariable <- colnames(DPA.Predictors.Numeric)[DPA_HighlyCorrelated[j]]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_HighlyCorrelatedRemovedVariable))
  }

  ##################################
  # Filtering out columns with high correlation
  #################################
  DPA_ExcludedHighCorrelation <- DPA[,-DPA_HighlyCorrelated]

  ##################################
  # Gathering descriptive statistics
  ##################################
  (DPA_ExcludedHighCorrelation_Skimmed <- skim(DPA_ExcludedHighCorrelation))
  
  ###################################
  # Verifying the data dimensions
  ###################################
  dim(DPA_ExcludedHighCorrelation)

}

```

</details>

###  1.3.4 Linear Dependencies
|
| Linear dependency data assessment:
|
| **[A]** No linear dependencies noted for any subset of variables using the preprocessing summary from the <mark style="background-color: #CCECFF">**caret**</mark> package applying the <span style="color: #0000FF">findLinearCombos</span> method which utilizes the QR decomposition of a matrix to enumerate sets of linear combinations (if they exist). 
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.4, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- Sonar_Train

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("Class")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,sapply(DPA.Predictors, is.numeric)]

##################################
# Identifying the linearly dependent variables
##################################
DPA_LinearlyDependent <- findLinearCombos(DPA.Predictors.Numeric)

(DPA_LinearlyDependentCount <- length(DPA_LinearlyDependent$linearCombos))

if (DPA_LinearlyDependentCount == 0) {
  print("No linearly dependent predictors noted.")
} else {
  print(paste0("Linear dependency observed for ",
               (DPA_LinearlyDependentCount),
               " subset(s) of numeric variable(s)."))

  for (i in 1:DPA_LinearlyDependentCount) {
    DPA_LinearlyDependentSubset <- colnames(DPA.Predictors.Numeric)[DPA_LinearlyDependent$linearCombos[[i]]]
    print(paste0("Linear dependent variable(s) for subset ",
                 i,
                 " include: ",
                 DPA_LinearlyDependentSubset))
  }

}

##################################
# Identifying the linearly dependent variables for removal
##################################

if (DPA_LinearlyDependentCount > 0) {
  DPA_LinearlyDependent <- findLinearCombos(DPA.Predictors.Numeric)

  DPA_LinearlyDependentForRemoval <- length(DPA_LinearlyDependent$remove)

  print(paste0("Linear dependency can be resolved by removing ",
               (DPA_LinearlyDependentForRemoval),
               " numeric variable(s)."))

  for (j in 1:DPA_LinearlyDependentForRemoval) {
  DPA_LinearlyDependentRemovedVariable <- colnames(DPA.Predictors.Numeric)[DPA_LinearlyDependent$remove[j]]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_LinearlyDependentRemovedVariable))
  }

  ##################################
  # Filtering out columns with linear dependency
  #################################
  DPA_ExcludedLinearlyDependent <- DPA[,-DPA_LinearlyDependent$remove]

  ##################################
  # Gathering descriptive statistics
  ##################################
  (DPA_ExcludedLinearlyDependent_Skimmed <- skim(DPA_ExcludedLinearlyDependent))
  
  ###################################
  # Verifying the data dimensions
  ###################################
  dim(DPA_ExcludedLinearlyDependent)

} else {
  
  ###################################
  # Verifying the data dimensions
  ###################################
  dim(DPA)
  
}
```

</details>

###  1.3.5 Shape Transformation
|
| Data transformation assessment:
|
| **[A]** A number of numeric variables in the dataset were observed to be right-skewed which required shape transformation for data distribution stability. Considering that all numeric variables were strictly positive values, the <span style="color: #0000FF">BoxCox</span> method from the <mark style="background-color: #CCECFF">**caret**</mark> package was used to transform their distributional shapes.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.5, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- Sonar_Train

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("Class")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,sapply(DPA.Predictors, is.numeric)]

##################################
# Applying a Box-Cox transformation
##################################
DPA_BoxCox <- preProcess(DPA.Predictors.Numeric, method = c("BoxCox"))
DPA_BoxCoxTransformed <- predict(DPA_BoxCox, DPA.Predictors.Numeric)

##################################
# Gathering descriptive statistics
##################################
(DPA_BoxCoxTransformedSkimmed <- skim(DPA_BoxCoxTransformed))

###################################
# Verifying the data dimensions
###################################
dim(DPA_BoxCoxTransformed)

```

</details>

###  1.3.6 Centering and Scaling
|
| Centering and scaling data assessment:
|
| **[A]** To maintain numerical stability during modelling, centering and scaling transformations were applied on the transformed numeric variables. The <span style="color: #0000FF">center</span> method from the <mark style="background-color: #CCECFF">**caret**</mark> package was implemented which subtracts the average value of a numeric variable to all the values. As a result of centering, the variables had zero mean values. In addition, the <span style="color: #0000FF">scale</span> method, also from the <mark style="background-color: #CCECFF">**caret**</mark> package, was applied which performs a center transformation with each value of the variable divided by its standard deviation. Scaling the data coerced the values to have a common standard deviation of one.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.6, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- Sonar_Train

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("Class")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,sapply(DPA.Predictors, is.numeric)]

##################################
# Applying a Box-Cox transformation
##################################
DPA_BoxCox <- preProcess(DPA.Predictors.Numeric, method = c("BoxCox"))
DPA_BoxCoxTransformed <- predict(DPA_BoxCox, DPA.Predictors.Numeric)

##################################
# Applying a center and scale data transformation
##################################
DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaled <- preProcess(DPA_BoxCoxTransformed, method = c("center","scale"))
DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaledTransformed <- predict(DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaled, DPA_BoxCoxTransformed)

##################################
# Gathering descriptive statistics
##################################
(DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaledTransformedSkimmed <- skim(DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaledTransformed))

###################################
# Verifying the data dimensions
###################################
dim(DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaledTransformed)

```

</details>

###  1.3.7 Pre-Processed Dataset
|
| Preliminary dataset assessment:
|
| **[A]** 136 rows (observations)
|      **[A.1]** Train Set = 136 observations with class ratio of 80:20
| 
| **[B]** 3 columns (variables)
|      **[B.1]** 1/3 response = <span style="color: #FF0000">Class</span> variable (factor)
|             **[B.1.1]** Levels = <span style="color: #FF0000">Class=R</span> < <span style="color: #FF0000">Class=M</span>
|      **[B.2]** 2/3 predictors = All remaining variables (2/2 numeric)
|
| **[C]** Pre-processing actions applied:
|      **[C.1]** Centering, scaling and shape transformation applied to improve data quality
|      **[C.2]** No outlier treatment applied since the high values noted were contextually valid and sensible 
|      **[C.3]** No predictors removed due to zero or near-zero variance 
|      **[C.4]** No predictors removed due to high correlation
|      **[C.5]** No predictors removed due to linear dependencies
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.7, warning=FALSE, message=FALSE}
##################################
# Creating the pre-modelling
# train set
##################################
Class <- DPA$Class 
PMA.Predictors.Numeric  <- DPA.Predictors.Numeric_BoxCoxTransformed_CenteredScaledTransformed
PMA_BoxCoxTransformed_CenteredScaledTransformed <- cbind(Class,PMA.Predictors.Numeric)
PMA_PreModelling_Train <- PMA_BoxCoxTransformed_CenteredScaledTransformed

##################################
# Gathering descriptive statistics
##################################
(PMA_PreModelling_Train_Skimmed <- skim(PMA_PreModelling_Train))

###################################
# Verifying the data dimensions
# for the train set
###################################
dim(PMA_PreModelling_Train)

```

</details>

## 1.4 Data Exploration
|
| Exploratory data analysis:
|
| **[A]** Both <span style="color: #FF0000">V1</span> and <span style="color: #FF0000">V11</span> numeric variables demonstrated differential relationships with the <span style="color: #FF0000">Class</span> response variable.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.4, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
EDA <- PMA_PreModelling_Train

##################################
# Listing all predictors
##################################
EDA.Predictors <- EDA[,!names(EDA) %in% c("Class")]

##################################
# Listing all numeric predictors
##################################
EDA.Predictors.Numeric <- EDA.Predictors[,sapply(EDA.Predictors, is.numeric)]
ncol(EDA.Predictors.Numeric)
names(EDA.Predictors.Numeric)

##################################
# Formulating the box plots
##################################
featurePlot(x = EDA.Predictors.Numeric, 
            y = EDA$Class,
            plot = "box",
            scales = list(x = list(relation="free", rot = 90), 
                          y = list(relation="free")),
            adjust = 1.5, 
            pch = "|")

```

</details>

## 1.5 Oversampling and Undersampling Algorithms Applied for Class Imbalance using Logistic Regression

###  1.5.1 Original Data (LR)
|
| [Logistic Regression](http://dx.doi.org/10.2139/ssrn.360300) models the relationship between the probability of an event (among two outcome levels) by having the log-odds of the event be a linear combination of a set of predictors weighted by their respective parameter estimates. The parameters are estimated via maximum likelihood estimation by testing different values through multiple iterations to optimize for the best fit of log odds. All of these iterations produce the log likelihood function, and logistic regression seeks to maximize this function to find the best parameter estimates. Given the optimal parameters, the conditional probabilities for each observation can be calculated, logged, and summed together to yield a predicted probability.
|
| **[A]** The class ratio of the original data was noted at 80:20.
|      **[A.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[A.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 25 instances
|
| **[B]** The logistic regression model from the <mark style="background-color: #CCECFF">**stats**</mark> package was implemented. The <span style="color: #FF0000">Class</span> response was regressed against the <span style="color: #FF0000">V1</span> and <span style="color: #FF0000">V11</span> predictors.
|
| **[C]** The logistic curve formulated by plotting the predicted probabilities against the classification index using the logit values showed a skewed logistic profile with a longer tail for the predicted points belonging to the majority class.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.1, warning=FALSE, message=FALSE}
##################################
# Creating a local object
# for the train set
##################################
PMA_PreModelling_Train_LR <- PMA_PreModelling_Train
PMA_PreModelling_Train_LR$Label <- rep("LR",nrow(PMA_PreModelling_Train_LR))

##################################
# Verifying the class distribution
# for the original data
##################################
table(PMA_PreModelling_Train_LR$Class) 

##################################
# Visualizing the imbalanced data set
##################################
ggplot(PMA_PreModelling_Train, aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "Original Imbalanced Data Set") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

##################################
# Formulating the structure of the
# Logistic Regression model
##################################
LR_Model <- glm(Class ~ V1 + V11,
                data = PMA_PreModelling_Train_LR,
                family = binomial)

##################################
# Consolidating the model results
##################################
summary(LR_Model)

LR_Model_Coef <- (as.data.frame(LR_Model$coefficients))
LR_Model_Coef$Coef <- rownames(LR_Model_Coef)
LR_Model_Coef$Model <- rep("LR",nrow(LR_Model_Coef))
colnames(LR_Model_Coef) <- c("Estimates","Coefficients","Model")
print(LR_Model_Coef, rownames=FALSE)

##################################
# Computing the model predictions
##################################
(LR_Model_Probabilities <- predict(LR_Model, 
                              type = c("response")))

##################################
# Creating a classification index
# based from the model predictions
##################################
(LR_Model_Indices <- predict(LR_Model, 
                           type = c("link")))
max(LR_Model_Indices)
min(LR_Model_Indices)

##################################
# Consolidating the model probabilities
# and classification index
# based from the model predictions
##################################
LR_Model_Predictions <- as.data.frame(PMA_PreModelling_Train_LR)
LR_Model_Predictions$LR_Prob <- LR_Model_Probabilities
LR_Model_Predictions$LR_LP <- LR_Model_Indices
LR_Model_Predictions$Class <- as.factor(LR_Model_Predictions$Class)
LR_Model_Predictions$Label <- rep("LR",nrow(LR_Model_Predictions))

##################################
# Formulating the probability curve
# using the consolidated model predictions
##################################
LR_Model_Predictions %>%
  ggplot(aes(x = LR_LP ,
             y = LR_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  ggtitle("Estimated Rock Detection Probabilities Based on Classification Index : Logistic Regression") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

```

</details>

###  1.5.2 Undersampling - Random Downsampling  (LR_US_DOWNSAMPLE)
|
| [Random Downsampling](https://dl.acm.org/doi/10.1145/1007730.1007735) performs a random removal of rows for the majority class instances to make the occurrence of levels with the minority class equal.
|
| [Logistic Regression](http://dx.doi.org/10.2139/ssrn.360300) models the relationship between the probability of an event (among two outcome levels) by having the log-odds of the event be a linear combination of a set of predictors weighted by their respective parameter estimates. The parameters are estimated via maximum likelihood estimation by testing different values through multiple iterations to optimize for the best fit of log odds. All of these iterations produce the log likelihood function, and logistic regression seeks to maximize this function to find the best parameter estimates. Given the optimal parameters, the conditional probabilities for each observation can be calculated, logged, and summed together to yield a predicted probability.
|
| **[A]** The class ratio of the original data was noted at 80:20.
|      **[A.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[A.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 25 instances
|
| **[B]** The class ratio of the undersampled data was noted at 50:50, although the number of instances was significantly decreased by 63%.
|      **[B.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 25 instances
|      **[B.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 25 instances
|
| **[C]** The logistic regression model from the <mark style="background-color: #CCECFF">**stats**</mark> package was implemented. The <span style="color: #FF0000">Class</span> response was regressed against the <span style="color: #FF0000">V1</span> and <span style="color: #FF0000">V11</span> predictors.
|
| **[D]** The logistic curve formulated by plotting the predicted probabilities against the classification index using the logit values showed a sufficiently balanced logistic profile for the predicted points from both the majority and minority classes, although the distribution of instances was relatively sparse.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.2, warning=FALSE, message=FALSE}
##################################
# Visualizing the imbalanced data set
##################################
ggplot(PMA_PreModelling_Train, aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "Without Undersampling - Random Downsampling") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

##################################
# Implementing US_DOWNSAMPLE
# Visualizing the undersampled data using US_DOWNSAMPLE
##################################
recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_downsample(Class, seed=123456789) %>%
  prep() %>%
  bake(new_data = NULL) %>%
  ggplot(aes(V1, V11, color = Class)) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  labs(title = "With Undersampling - Random Downsample") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

US_DOWNSAMPLE <- recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_downsample(Class, seed=123456789) %>%
  prep()

PMA_PreModelling_Train_LR_US_DOWNSAMPLE <- US_DOWNSAMPLE %>%
bake(new_data = NULL)

(PMA_PreModelling_Train_LR_US_DOWNSAMPLE <- as.data.frame(PMA_PreModelling_Train_LR_US_DOWNSAMPLE))

PMA_PreModelling_Train_LR_US_DOWNSAMPLE$Label <- rep("LR_US_DOWNSAMPLE",nrow(PMA_PreModelling_Train_LR_US_DOWNSAMPLE))

##################################
# Verifying the class distribution
# for the undersampled data using US_DOWNSAMPLE
##################################
table(PMA_PreModelling_Train_LR_US_DOWNSAMPLE$Class) 

##################################
# Formulating the structure of the
# Logistic Regression model
##################################
LR_US_DOWNSAMPLE_Model <- glm(Class ~ V1 + V11,
                data = PMA_PreModelling_Train_LR_US_DOWNSAMPLE,
                family = binomial)

##################################
# Consolidating the model results
##################################
summary(LR_US_DOWNSAMPLE_Model)

LR_US_DOWNSAMPLE_Model_Coef <- (as.data.frame(LR_US_DOWNSAMPLE_Model$coefficients))
LR_US_DOWNSAMPLE_Model_Coef$Coef <- rownames(LR_US_DOWNSAMPLE_Model_Coef)
LR_US_DOWNSAMPLE_Model_Coef$Model <- rep("LR_US_DOWNSAMPLE",nrow(LR_US_DOWNSAMPLE_Model_Coef))
colnames(LR_US_DOWNSAMPLE_Model_Coef) <- c("Estimates","Coefficients","Model")
print(LR_US_DOWNSAMPLE_Model_Coef, rownames=FALSE)

##################################
# Computing the model predictions
##################################
(LR_US_DOWNSAMPLE_Model_Probabilities <- predict(LR_US_DOWNSAMPLE_Model, 
                              type = c("response")))

##################################
# Creating a classification index
# based from the model predictions
##################################
(LR_US_DOWNSAMPLE_Model_Indices <- predict(LR_US_DOWNSAMPLE_Model, 
                           type = c("link")))
max(LR_US_DOWNSAMPLE_Model_Indices)
min(LR_US_DOWNSAMPLE_Model_Indices)

##################################
# Consolidating the model probabilities
# and classification index
# based from the model predictions
##################################
LR_US_DOWNSAMPLE_Model_Predictions <- as.data.frame(PMA_PreModelling_Train_LR_US_DOWNSAMPLE)
LR_US_DOWNSAMPLE_Model_Predictions$LR_US_DOWNSAMPLE_Prob <- LR_US_DOWNSAMPLE_Model_Probabilities
LR_US_DOWNSAMPLE_Model_Predictions$LR_US_DOWNSAMPLE_LP <- LR_US_DOWNSAMPLE_Model_Indices
LR_US_DOWNSAMPLE_Model_Predictions$Class <- as.factor(LR_US_DOWNSAMPLE_Model_Predictions$Class)
LR_US_DOWNSAMPLE_Model_Predictions$Label <- rep("LR_US_DOWNSAMPLE",nrow(LR_US_DOWNSAMPLE_Model_Predictions))

##################################
# Formulating the probability curve
# using the consolidated model predictions
##################################
LR_US_DOWNSAMPLE_Model_Predictions %>%
  ggplot(aes(x = LR_US_DOWNSAMPLE_LP ,
             y = LR_US_DOWNSAMPLE_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  ggtitle("Estimated Rock Detection Probabilities Based on Classification Index : Logistic Regression (US_DOWNSAMPLE)") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

```

</details>

###  1.5.3 Oversampling - Random Upsampling  (LR_US_UPSAMPLE)
|
| [Random Upsampling](https://dl.acm.org/doi/10.1145/1007730.1007735) performs a random replication of rows for the minority class instances to make the occurrence of levels with the majority class equal.
|
| [Logistic Regression](http://dx.doi.org/10.2139/ssrn.360300) models the relationship between the probability of an event (among two outcome levels) by having the log-odds of the event be a linear combination of a set of predictors weighted by their respective parameter estimates. The parameters are estimated via maximum likelihood estimation by testing different values through multiple iterations to optimize for the best fit of log odds. All of these iterations produce the log likelihood function, and logistic regression seeks to maximize this function to find the best parameter estimates. Given the optimal parameters, the conditional probabilities for each observation can be calculated, logged, and summed together to yield a predicted probability.
|
| **[A]** The class ratio of the original data was noted at 80:20.
|      **[A.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[A.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 25 instances
|
| **[B]** The class ratio of the oversampled data was noted at 50:50, although majority of the added instances were not unique values but replicates of the rows from the minority class.
|      **[B.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[B.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 111 instances
|
| **[C]** The logistic regression model from the <mark style="background-color: #CCECFF">**stats**</mark> package was implemented. The <span style="color: #FF0000">Class</span> response was regressed against the <span style="color: #FF0000">V1</span> and <span style="color: #FF0000">V11</span> predictors.
|
| **[D]** The logistic curve formulated by plotting the predicted probabilities against the classification index using the logit values showed a sufficiently balanced logistic profile for the predicted points from both the majority and minority classes, although the ratio of the uniques values and number of instances was relatively low.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.3, warning=FALSE, message=FALSE}
##################################
# Visualizing the imbalanced data set
##################################
ggplot(PMA_PreModelling_Train, aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "Without Oversampling - Random Upsampling") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

##################################
# Implementing OS_UPSAMPLE
# Visualizing the oversampled data using OS_UPSAMPLE
##################################
recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_upsample(Class, seed=123456789) %>%
  prep() %>%
  bake(new_data = NULL) %>%
  ggplot(aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "With Undersampling - Random Upsample") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

OS_UPSAMPLE <- recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_upsample(Class, seed=123456789) %>%
  prep()

PMA_PreModelling_Train_LR_OS_UPSAMPLE <- OS_UPSAMPLE %>%
bake(new_data = NULL)

(PMA_PreModelling_Train_LR_OS_UPSAMPLE <- as.data.frame(PMA_PreModelling_Train_LR_OS_UPSAMPLE))

PMA_PreModelling_Train_LR_OS_UPSAMPLE$Label <- rep("LR_OS_UPSAMPLE",nrow(PMA_PreModelling_Train_LR_OS_UPSAMPLE))

##################################
# Verifying the class distribution
# for the oversampled data using OS_UPSAMPLE
##################################
table(PMA_PreModelling_Train_LR_OS_UPSAMPLE$Class) 

##################################
# Formulating the structure of the
# Logistic Regression model
##################################
LR_OS_UPSAMPLE_Model <- glm(Class ~ V1 + V11,
                data = PMA_PreModelling_Train_LR_OS_UPSAMPLE,
                family = binomial)

##################################
# Consolidating the model results
##################################
summary(LR_OS_UPSAMPLE_Model)

LR_OS_UPSAMPLE_Model_Coef <- (as.data.frame(LR_OS_UPSAMPLE_Model$coefficients))
LR_OS_UPSAMPLE_Model_Coef$Coef <- rownames(LR_OS_UPSAMPLE_Model_Coef)
LR_OS_UPSAMPLE_Model_Coef$Model <- rep("LR_OS_UPSAMPLE",nrow(LR_OS_UPSAMPLE_Model_Coef))
colnames(LR_OS_UPSAMPLE_Model_Coef) <- c("Estimates","Coefficients","Model")
print(LR_OS_UPSAMPLE_Model_Coef, rownames=FALSE)

##################################
# Computing the model predictions
##################################
(LR_OS_UPSAMPLE_Model_Probabilities <- predict(LR_OS_UPSAMPLE_Model, 
                              type = c("response")))

##################################
# Creating a classification index
# based from the model predictions
##################################
(LR_OS_UPSAMPLE_Model_Indices <- predict(LR_OS_UPSAMPLE_Model, 
                           type = c("link")))
max(LR_OS_UPSAMPLE_Model_Indices)
min(LR_OS_UPSAMPLE_Model_Indices)

##################################
# Consolidating the model probabilities
# and classification index
# based from the model predictions
##################################
LR_OS_UPSAMPLE_Model_Predictions <- as.data.frame(PMA_PreModelling_Train_LR_OS_UPSAMPLE)
LR_OS_UPSAMPLE_Model_Predictions$LR_OS_UPSAMPLE_Prob <- LR_OS_UPSAMPLE_Model_Probabilities
LR_OS_UPSAMPLE_Model_Predictions$LR_OS_UPSAMPLE_LP <- LR_OS_UPSAMPLE_Model_Indices
LR_OS_UPSAMPLE_Model_Predictions$Class <- as.factor(LR_OS_UPSAMPLE_Model_Predictions$Class)
LR_OS_UPSAMPLE_Model_Predictions$Label <- rep("LR_OS_UPSAMPLE",nrow(LR_OS_UPSAMPLE_Model_Predictions))

##################################
# Formulating the probability curve
# using the consolidated model predictions
##################################
LR_OS_UPSAMPLE_Model_Predictions %>%
  ggplot(aes(x = LR_OS_UPSAMPLE_LP ,
             y = LR_OS_UPSAMPLE_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  ggtitle("Estimated Rock Detection Probabilities Based on Classification Index : Logistic Regression (OS_UPSAMPLE)") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

```

</details>

###  1.5.4 Undersampling - Near Miss Algorithm  (LR_US_NEARMISS)
|
| [Near Miss Algorithm](https://www.academia.edu/12815658/knn_approach_to_unbalanced_data_distributions_A_case_study_involving_information_extraction) removes majority class instances by undersampling points in the majority class which have the smallest mean distance to the defined nearest points in the minority class and based on their distance to other points in the same class. 
|
| [Logistic Regression](http://dx.doi.org/10.2139/ssrn.360300) models the relationship between the probability of an event (among two outcome levels) by having the log-odds of the event be a linear combination of a set of predictors weighted by their respective parameter estimates. The parameters are estimated via maximum likelihood estimation by testing different values through multiple iterations to optimize for the best fit of log odds. All of these iterations produce the log likelihood function, and logistic regression seeks to maximize this function to find the best parameter estimates. Given the optimal parameters, the conditional probabilities for each observation can be calculated, logged, and summed together to yield a predicted probability.
|
| **[A]** The class ratio of the original data was noted at 80:20.
|      **[A.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[A.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 25 instances
|
| **[B]** The class ratio of the undersampled data was noted at 50:50, although the number of instances was significantly decreased by 63%.
|      **[B.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 25 instances
|      **[B.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 25 instances
|
| **[C]** The logistic regression model from the <mark style="background-color: #CCECFF">**stats**</mark> package was implemented. The <span style="color: #FF0000">Class</span> response was regressed against the <span style="color: #FF0000">V1</span> and <span style="color: #FF0000">V11</span> predictors.
|
| **[D]** The logistic curve formulated by plotting the predicted probabilities against the classification index using the logit values showed a sufficiently balanced logistic profile for the predicted points from both the majority and minority classes, although the distribution of instances was relatively sparse.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.4, warning=FALSE, message=FALSE}
##################################
# Visualizing the imbalanced data set
##################################
ggplot(PMA_PreModelling_Train, aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "Without Undersampling - Near Miss Algorithm") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

##################################
# Implementing US_NEARMISS
# Visualizing the undersampled data using US_NEARMISS
##################################
recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_nearmiss(Class, seed=123456789) %>%
  prep() %>%
  bake(new_data = NULL) %>%
  ggplot(aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "With Undersampling - Near Miss Algorithm") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

US_NEARMISS <- recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_nearmiss(Class, seed=123456789) %>%
  prep()

PMA_PreModelling_Train_LR_US_NEARMISS <- US_NEARMISS %>%
bake(new_data = NULL)

(PMA_PreModelling_Train_LR_US_NEARMISS <- as.data.frame(PMA_PreModelling_Train_LR_US_NEARMISS))

PMA_PreModelling_Train_LR_US_NEARMISS$Label <- rep("LR_US_NEARMISS",nrow(PMA_PreModelling_Train_LR_US_NEARMISS))

##################################
# Verifying the class distribution
# for the undersampled data using US_NEARMISS
##################################
table(PMA_PreModelling_Train_LR_US_NEARMISS$Class) 

##################################
# Formulating the structure of the
# Logistic Regression model
##################################
LR_US_NEARMISS_Model <- glm(Class ~ V1 + V11,
                data = PMA_PreModelling_Train_LR_US_NEARMISS,
                family = binomial)

##################################
# Consolidating the model results
##################################
summary(LR_US_NEARMISS_Model)

LR_US_NEARMISS_Model_Coef <- (as.data.frame(LR_US_NEARMISS_Model$coefficients))
LR_US_NEARMISS_Model_Coef$Coef <- rownames(LR_US_NEARMISS_Model_Coef)
LR_US_NEARMISS_Model_Coef$Model <- rep("LR_US_NEARMISS",nrow(LR_US_NEARMISS_Model_Coef))
colnames(LR_US_NEARMISS_Model_Coef) <- c("Estimates","Coefficients","Model")
print(LR_US_NEARMISS_Model_Coef, rownames=FALSE)

##################################
# Computing the model predictions
##################################
(LR_US_NEARMISS_Model_Probabilities <- predict(LR_US_NEARMISS_Model, 
                              type = c("response")))

##################################
# Creating a classification index
# based from the model predictions
##################################
(LR_US_NEARMISS_Model_Indices <- predict(LR_US_NEARMISS_Model, 
                           type = c("link")))
max(LR_US_NEARMISS_Model_Indices)
min(LR_US_NEARMISS_Model_Indices)

##################################
# Consolidating the model probabilities
# and classification index
# based from the model predictions
##################################
LR_US_NEARMISS_Model_Predictions <- as.data.frame(PMA_PreModelling_Train_LR_US_NEARMISS)
LR_US_NEARMISS_Model_Predictions$LR_US_NEARMISS_Prob <- LR_US_NEARMISS_Model_Probabilities
LR_US_NEARMISS_Model_Predictions$LR_US_NEARMISS_LP <- LR_US_NEARMISS_Model_Indices
LR_US_NEARMISS_Model_Predictions$Class <- as.factor(LR_US_NEARMISS_Model_Predictions$Class)
LR_US_NEARMISS_Model_Predictions$Label <- rep("LR_US_NEARMISS",nrow(LR_US_NEARMISS_Model_Predictions))

##################################
# Formulating the probability curve
# using the consolidated model predictions
##################################
LR_US_NEARMISS_Model_Predictions %>%
  ggplot(aes(x = LR_US_NEARMISS_LP ,
             y = LR_US_NEARMISS_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  ggtitle("Estimated Rock Detection Probabilities Based on Classification Index : Logistic Regression (US_NEARMISS)") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

```

</details>

###  1.5.5 Undersampling - Tomek Links  (LR_US_TOMEK)
|
| [Tomek Links](https://ieeexplore.ieee.org/document/4309452) remove majority class instances of tomek links referring to a pair of points from different classes and are each others nearest neighbors
|
| [Logistic Regression](http://dx.doi.org/10.2139/ssrn.360300) models the relationship between the probability of an event (among two outcome levels) by having the log-odds of the event be a linear combination of a set of predictors weighted by their respective parameter estimates. The parameters are estimated via maximum likelihood estimation by testing different values through multiple iterations to optimize for the best fit of log odds. All of these iterations produce the log likelihood function, and logistic regression seeks to maximize this function to find the best parameter estimates. Given the optimal parameters, the conditional probabilities for each observation can be calculated, logged, and summed together to yield a predicted probability.
|
| **[A]** The class ratio of the original data was noted at 80:20.
|      **[A.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[A.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 25 instances
|
| **[B]** The class ratio of the undersampled data was noted at 85:15 which performed worse than the original data.
|      **[B.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 102 instances
|      **[B.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 16 instances
|
| **[C]** The logistic regression model from the <mark style="background-color: #CCECFF">**stats**</mark> package was implemented. The <span style="color: #FF0000">Class</span> response was regressed against the <span style="color: #FF0000">V1</span> and <span style="color: #FF0000">V11</span> predictors.
|
| **[D]** The logistic curve formulated by plotting the predicted probabilities against the classification index using the logit values showed a skewed logistic profile with a longer tail for the predicted points belonging to the majority class.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.5, warning=FALSE, message=FALSE}
##################################
# Visualizing the imbalanced data set
##################################
ggplot(PMA_PreModelling_Train, aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "Without Undersampling - Tomek Links") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

##################################
# Implementing US_TOMEK
# Visualizing the undersampled data using US_TOMEK
##################################
recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_tomek(Class, seed=123456789) %>%
  prep() %>%
  bake(new_data = NULL) %>%
  ggplot(aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "With Undersampling - Tomek Links") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

US_TOMEK <- recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_tomek(Class, seed=123456789) %>%
  prep()

PMA_PreModelling_Train_LR_US_TOMEK <- US_TOMEK %>%
bake(new_data = NULL)

(PMA_PreModelling_Train_LR_US_TOMEK <- as.data.frame(PMA_PreModelling_Train_LR_US_TOMEK))

PMA_PreModelling_Train_LR_US_TOMEK$Label <- rep("LR_US_TOMEK",nrow(PMA_PreModelling_Train_LR_US_TOMEK))

##################################
# Verifying the class distribution
# for the undersampled data using US_TOMEK
##################################
table(PMA_PreModelling_Train_LR_US_TOMEK$Class) 

##################################
# Formulating the structure of the
# Logistic Regression model
##################################
LR_US_TOMEK_Model <- glm(Class ~ V1 + V11,
                data = PMA_PreModelling_Train_LR_US_TOMEK,
                family = binomial)

##################################
# Consolidating the model results
##################################
summary(LR_US_TOMEK_Model)

LR_US_TOMEK_Model_Coef <- (as.data.frame(LR_US_TOMEK_Model$coefficients))
LR_US_TOMEK_Model_Coef$Coef <- rownames(LR_US_TOMEK_Model_Coef)
LR_US_TOMEK_Model_Coef$Model <- rep("LR_US_TOMEK",nrow(LR_US_TOMEK_Model_Coef))
colnames(LR_US_TOMEK_Model_Coef) <- c("Estimates","Coefficients","Model")
print(LR_US_TOMEK_Model_Coef, rownames=FALSE)

##################################
# Computing the model predictions
##################################
(LR_US_TOMEK_Model_Probabilities <- predict(LR_US_TOMEK_Model, 
                              type = c("response")))

##################################
# Creating a classification index
# based from the model predictions
##################################
(LR_US_TOMEK_Model_Indices <- predict(LR_US_TOMEK_Model, 
                           type = c("link")))
max(LR_US_TOMEK_Model_Indices)
min(LR_US_TOMEK_Model_Indices)

##################################
# Consolidating the model probabilities
# and classification index
# based from the model predictions
##################################
LR_US_TOMEK_Model_Predictions <- as.data.frame(PMA_PreModelling_Train_LR_US_TOMEK)
LR_US_TOMEK_Model_Predictions$LR_US_TOMEK_Prob <- LR_US_TOMEK_Model_Probabilities
LR_US_TOMEK_Model_Predictions$LR_US_TOMEK_LP <- LR_US_TOMEK_Model_Indices
LR_US_TOMEK_Model_Predictions$Class <- as.factor(LR_US_TOMEK_Model_Predictions$Class)
LR_US_TOMEK_Model_Predictions$Label <- rep("LR_US_TOMEK",nrow(LR_US_TOMEK_Model_Predictions))

##################################
# Formulating the probability curve
# using the consolidated model predictions
##################################
LR_US_TOMEK_Model_Predictions %>%
  ggplot(aes(x = LR_US_TOMEK_LP ,
             y = LR_US_TOMEK_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  ggtitle("Estimated Rock Detection Probabilities Based on Classification Index : Logistic Regression (US_TOMEK)") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

```

</details>

###  1.5.6 Oversampling - Adaptive Synthetic Algorithm (LR_OS_ADASYN)
|
| [Adaptive Synthetic Algorithm](https://ieeexplore.ieee.org/document/4633969) uses a weighted distribution for different minority class instances according to their level of difficulty in learning. Synthetic data is generated for minority class instances that are harder to learn compared to those minority instances that are easier to learn. The algorithm improves learning with respect to the data distributions by reducing the bias introduced by the class imbalance and adaptively shifting the classification decision boundary toward the difficult examples.
|
| [Logistic Regression](http://dx.doi.org/10.2139/ssrn.360300) models the relationship between the probability of an event (among two outcome levels) by having the log-odds of the event be a linear combination of a set of predictors weighted by their respective parameter estimates. The parameters are estimated via maximum likelihood estimation by testing different values through multiple iterations to optimize for the best fit of log odds. All of these iterations produce the log likelihood function, and logistic regression seeks to maximize this function to find the best parameter estimates. Given the optimal parameters, the conditional probabilities for each observation can be calculated, logged, and summed together to yield a predicted probability.
|
| **[A]** The class ratio of the original data was noted at 80:20.
|      **[A.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[A.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 25 instances
|
| **[B]** The class ratio of the oversampled data was noted at 50:50 with majority of the added instances being unique values for the minority class.
|      **[B.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[B.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 111 instances
|
| **[C]** The logistic regression model from the <mark style="background-color: #CCECFF">**stats**</mark> package was implemented. The <span style="color: #FF0000">Class</span> response was regressed against the <span style="color: #FF0000">V1</span> and <span style="color: #FF0000">V11</span> predictors.
|
| **[D]** The logistic curve formulated by plotting the predicted probabilities against the classification index using the logit values showed a sufficiently balanced logistic profile for the predicted points from both the majority and minority classes. Although the ratio of the uniques values and number of instances was relatively high, the added instances tended to cluster at the center of the data distribution.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.6, warning=FALSE, message=FALSE}
##################################
# Visualizing the imbalanced data set
##################################
ggplot(PMA_PreModelling_Train, aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  labs(title = "Without Oversampling - Adaptive Synthetic Algorithm") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

##################################
# Implementing OS_ADASYN
# Visualizing the oversampled data using OS_ADASYN
##################################
recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_adasyn(Class, seed=123456789) %>%
  prep() %>%
  bake(new_data = NULL) %>%
  ggplot(aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "With Oversampling - Adaptive Synthetic Algorithm") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

OS_ADASYN <- recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_adasyn(Class, seed=123456789) %>%
  prep()

PMA_PreModelling_Train_LR_OS_ADASYN <- OS_ADASYN %>%
bake(new_data = NULL)

(PMA_PreModelling_Train_LR_OS_ADASYN <- as.data.frame(PMA_PreModelling_Train_LR_OS_ADASYN))

PMA_PreModelling_Train_LR_OS_ADASYN$Label <- rep("LR_OS_ADASYN",nrow(PMA_PreModelling_Train_LR_OS_ADASYN))

##################################
# Verifying the class distribution
# for the oversampled data using OS_ADASYN
##################################
table(PMA_PreModelling_Train_LR_OS_ADASYN$Class) 

##################################
# Formulating the structure of the
# Logistic Regression model
##################################
LR_OS_ADASYN_Model <- glm(Class ~ V1 + V11,
                data = PMA_PreModelling_Train_LR_OS_ADASYN,
                family = binomial)

##################################
# Consolidating the model results
##################################
summary(LR_OS_ADASYN_Model)

LR_OS_ADASYN_Model_Coef <- (as.data.frame(LR_OS_ADASYN_Model$coefficients))
LR_OS_ADASYN_Model_Coef$Coef <- rownames(LR_OS_ADASYN_Model_Coef)
LR_OS_ADASYN_Model_Coef$Model <- rep("LR_OS_ADASYN",nrow(LR_OS_ADASYN_Model_Coef))
colnames(LR_OS_ADASYN_Model_Coef) <- c("Estimates","Coefficients","Model")
print(LR_OS_ADASYN_Model_Coef, rownames=FALSE)

##################################
# Computing the model predictions
##################################
(LR_OS_ADASYN_Model_Probabilities <- predict(LR_OS_ADASYN_Model, 
                              type = c("response")))

##################################
# Creating a classification index
# based from the model predictions
##################################
(LR_OS_ADASYN_Model_Indices <- predict(LR_OS_ADASYN_Model, 
                           type = c("link")))
max(LR_OS_ADASYN_Model_Indices)
min(LR_OS_ADASYN_Model_Indices)

##################################
# Consolidating the model probabilities
# and classification index
# based from the model predictions
##################################
LR_OS_ADASYN_Model_Predictions <- as.data.frame(PMA_PreModelling_Train_LR_OS_ADASYN)
LR_OS_ADASYN_Model_Predictions$LR_OS_ADASYN_Prob <- LR_OS_ADASYN_Model_Probabilities
LR_OS_ADASYN_Model_Predictions$LR_OS_ADASYN_LP <- LR_OS_ADASYN_Model_Indices
LR_OS_ADASYN_Model_Predictions$Class <- as.factor(LR_OS_ADASYN_Model_Predictions$Class)
LR_OS_ADASYN_Model_Predictions$Label <- rep("LR_OS_ADASYN",nrow(LR_OS_ADASYN_Model_Predictions))

##################################
# Formulating the probability curve
# using the consolidated model predictions
##################################
LR_OS_ADASYN_Model_Predictions %>%
  ggplot(aes(x = LR_OS_ADASYN_LP ,
             y = LR_OS_ADASYN_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  ggtitle("Estimated Rock Detection Probabilities Based on Classification Index : Logistic Regression (OS_ADASYN)") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

```

</details>

###  1.5.7 Oversampling - Borderline Synthetic Minority Oversampling Technique  (LR_OS_BSMOTE)
|
| [Borderline Synthetic Minority Oversampling Technique](https://link.springer.com/chapter/10.1007/11538059_91) generates new instances of the minority class using nearest neighbors of these cases in the border region between classes. The algorithm initially classifies instances of the minority class into the noise, safe and danger categories. If the surrounding nearest neighbors are from the majority class, instances are denoted as noise data which will have have adverse effects on the data distribution and are thus not considered using synthetic data generation. Instances with more than half of the surrounding neighbors are from the same minority class are denoted as safe. Oversampling is only performed within minority class instances in the danger category which covers those with more than half of the nearest neighbors from the majority class.
|
| [Logistic Regression](http://dx.doi.org/10.2139/ssrn.360300) models the relationship between the probability of an event (among two outcome levels) by having the log-odds of the event be a linear combination of a set of predictors weighted by their respective parameter estimates. The parameters are estimated via maximum likelihood estimation by testing different values through multiple iterations to optimize for the best fit of log odds. All of these iterations produce the log likelihood function, and logistic regression seeks to maximize this function to find the best parameter estimates. Given the optimal parameters, the conditional probabilities for each observation can be calculated, logged, and summed together to yield a predicted probability.
|
| **[A]** The class ratio of the original data was noted at 80:20.
|      **[A.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[A.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 25 instances
|
| **[B]** The class ratio of the oversampled data was noted at 50:50 with majority of the added instances being unique values for the minority class.
|      **[B.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[B.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 111 instances
|
| **[C]** The logistic regression model from the <mark style="background-color: #CCECFF">**stats**</mark> package was implemented. The <span style="color: #FF0000">Class</span> response was regressed against the <span style="color: #FF0000">V1</span> and <span style="color: #FF0000">V11</span> predictors.
|
| **[D]** The logistic curve formulated by plotting the predicted probabilities against the classification index using the logit values showed a sufficiently balanced logistic profile for the predicted points from both the majority and minority classes. Minimal overlap between both classes was observed driving better differentiation although a minimal skew was still present due to a longer tail for the predicted points belonging to the majority class.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.7, warning=FALSE, message=FALSE}
##################################
# Visualizing the imbalanced data set
##################################
ggplot(PMA_PreModelling_Train, aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "Without Oversampling - Borderline Synthetic Minority Oversampling Technique") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

##################################
# Implementing OS_BSMOTE
# Visualizing the oversampled data using OS_BSMOTE
##################################
recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_bsmote(Class, seed=123456789) %>%
  prep() %>%
  bake(new_data = NULL) %>%
  ggplot(aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "With Oversampling - Borderline Synthetic Minority Oversampling Technique") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

OS_BSMOTE <- recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_bsmote(Class, seed=123456789) %>%
  prep()

PMA_PreModelling_Train_LR_OS_BSMOTE <- OS_BSMOTE %>%
bake(new_data = NULL)

(PMA_PreModelling_Train_LR_OS_BSMOTE <- as.data.frame(PMA_PreModelling_Train_LR_OS_BSMOTE))

PMA_PreModelling_Train_LR_OS_BSMOTE$Label <- rep("LR_OS_BSMOTE",nrow(PMA_PreModelling_Train_LR_OS_BSMOTE))

##################################
# Verifying the class distribution
# for the oversampled data using OS_BSMOTE
##################################
table(PMA_PreModelling_Train_LR_OS_BSMOTE$Class) 

##################################
# Formulating the structure of the
# Logistic Regression model
##################################
LR_OS_BSMOTE_Model <- glm(Class ~ V1 + V11,
                data = PMA_PreModelling_Train_LR_OS_BSMOTE,
                family = binomial)

##################################
# Consolidating the model results
##################################
summary(LR_OS_BSMOTE_Model)

LR_OS_BSMOTE_Model_Coef <- (as.data.frame(LR_OS_BSMOTE_Model$coefficients))
LR_OS_BSMOTE_Model_Coef$Coef <- rownames(LR_OS_BSMOTE_Model_Coef)
LR_OS_BSMOTE_Model_Coef$Model <- rep("LR_OS_BSMOTE",nrow(LR_OS_BSMOTE_Model_Coef))
colnames(LR_OS_BSMOTE_Model_Coef) <- c("Estimates","Coefficients","Model")
print(LR_OS_BSMOTE_Model_Coef, rownames=FALSE)

##################################
# Computing the model predictions
##################################
(LR_OS_BSMOTE_Model_Probabilities <- predict(LR_OS_BSMOTE_Model, 
                              type = c("response")))

##################################
# Creating a classification index
# based from the model predictions
##################################
(LR_OS_BSMOTE_Model_Indices <- predict(LR_OS_BSMOTE_Model, 
                           type = c("link")))
max(LR_OS_BSMOTE_Model_Indices)
min(LR_OS_BSMOTE_Model_Indices)

##################################
# Consolidating the model probabilities
# and classification index
# based from the model predictions
##################################
LR_OS_BSMOTE_Model_Predictions <- as.data.frame(PMA_PreModelling_Train_LR_OS_BSMOTE)
LR_OS_BSMOTE_Model_Predictions$LR_OS_BSMOTE_Prob <- LR_OS_BSMOTE_Model_Probabilities
LR_OS_BSMOTE_Model_Predictions$LR_OS_BSMOTE_LP <- LR_OS_BSMOTE_Model_Indices
LR_OS_BSMOTE_Model_Predictions$Class <- as.factor(LR_OS_BSMOTE_Model_Predictions$Class)
LR_OS_BSMOTE_Model_Predictions$Label <- rep("LR_OS_BSMOTE",nrow(LR_OS_BSMOTE_Model_Predictions))

##################################
# Formulating the probability curve
# using the consolidated model predictions
##################################
LR_OS_BSMOTE_Model_Predictions %>%
  ggplot(aes(x = LR_OS_BSMOTE_LP ,
             y = LR_OS_BSMOTE_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  ggtitle("Estimated Rock Detection Probabilities Based on Classification Index : Logistic Regression (OS_BSMOTE)") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

```

</details>

###  1.5.8 Oversampling - Synthetic Minority Oversampling Technique  (LR_OS_SMOTE)
|
| [Synthetic Minority Oversampling Technique](https://dl.acm.org/doi/10.5555/1622407.1622416) generates new minority instances between existing instances. The new instances created are not just the copy of existing minority cases, instead the algorithm takes sample of feature space for each target class and its neighbors and then generates new instances that combine the features of the target cases with features of its neighbors.
|
| [Logistic Regression](http://dx.doi.org/10.2139/ssrn.360300) models the relationship between the probability of an event (among two outcome levels) by having the log-odds of the event be a linear combination of a set of predictors weighted by their respective parameter estimates. The parameters are estimated via maximum likelihood estimation by testing different values through multiple iterations to optimize for the best fit of log odds. All of these iterations produce the log likelihood function, and logistic regression seeks to maximize this function to find the best parameter estimates. Given the optimal parameters, the conditional probabilities for each observation can be calculated, logged, and summed together to yield a predicted probability.
|
| **[A]** The class ratio of the original data was noted at 80:20.
|      **[A.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[A.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 25 instances
|
| **[B]** The class ratio of the oversampled data was noted at 50:50 with majority of the added instances being unique values for the minority class.
|      **[B.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[B.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 111 instances
|
| **[C]** The logistic regression model from the <mark style="background-color: #CCECFF">**stats**</mark> package was implemented. The <span style="color: #FF0000">Class</span> response was regressed against the <span style="color: #FF0000">V1</span> and <span style="color: #FF0000">V11</span> predictors.
|
| **[D]** The logistic curve formulated by plotting the predicted probabilities against the classification index using the logit values showed a sufficiently balanced logistic profile for the predicted points from both the majority and minority classes. Although the ratio of the unique values and number of instances was relatively high, a significant overlap between both classes was observed.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.8, warning=FALSE, message=FALSE}
##################################
# Visualizing the imbalanced data set
##################################
ggplot(PMA_PreModelling_Train, aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "Without Oversampling - Synthetic Minority Oversampling Technique") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

##################################
# Implementing OS_SMOTE
# Visualizing the oversampled data using OS_SMOTE
##################################
recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_smote(Class, seed=123456789) %>%
  prep() %>%
  bake(new_data = NULL) %>%
  ggplot(aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "With Oversampling - Synthetic Minority Oversampling Technique") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

OS_SMOTE <- recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_smote(Class, seed=123456789) %>%
  prep()

PMA_PreModelling_Train_LR_OS_SMOTE <- OS_SMOTE %>%
bake(new_data = NULL)

(PMA_PreModelling_Train_LR_OS_SMOTE <- as.data.frame(PMA_PreModelling_Train_LR_OS_SMOTE))
PMA_PreModelling_Train_LR_OS_SMOTE$Label <- rep("LR_OS_SMOTE",nrow(PMA_PreModelling_Train_LR_OS_SMOTE))

##################################
# Verifying the class distribution
# for the oversampled data using OS_SMOTE
##################################
table(PMA_PreModelling_Train_LR_OS_SMOTE$Class) 

##################################
# Formulating the structure of the
# Logistic Regression model
##################################
LR_OS_SMOTE_Model <- glm(Class ~ V1 + V11,
                data = PMA_PreModelling_Train_LR_OS_SMOTE,
                family = binomial)

##################################
# Consolidating the model results
##################################
summary(LR_OS_SMOTE_Model)

LR_OS_SMOTE_Model_Coef <- (as.data.frame(LR_OS_SMOTE_Model$coefficients))
LR_OS_SMOTE_Model_Coef$Coef <- rownames(LR_OS_SMOTE_Model_Coef)
LR_OS_SMOTE_Model_Coef$Model <- rep("LR_OS_SMOTE",nrow(LR_OS_SMOTE_Model_Coef))
colnames(LR_OS_SMOTE_Model_Coef) <- c("Estimates","Coefficients","Model")
print(LR_OS_SMOTE_Model_Coef, rownames=FALSE)

##################################
# Computing the model predictions
##################################
(LR_OS_SMOTE_Model_Probabilities <- predict(LR_OS_SMOTE_Model, 
                              type = c("response")))

##################################
# Creating a classification index
# based from the model predictions
##################################
(LR_OS_SMOTE_Model_Indices <- predict(LR_OS_SMOTE_Model, 
                           type = c("link")))
max(LR_OS_SMOTE_Model_Indices)
min(LR_OS_SMOTE_Model_Indices)

##################################
# Consolidating the model probabilities
# and classification index
# based from the model predictions
##################################
LR_OS_SMOTE_Model_Predictions <- as.data.frame(PMA_PreModelling_Train_LR_OS_SMOTE)
LR_OS_SMOTE_Model_Predictions$LR_OS_SMOTE_Prob <- LR_OS_SMOTE_Model_Probabilities
LR_OS_SMOTE_Model_Predictions$LR_OS_SMOTE_LP <- LR_OS_SMOTE_Model_Indices
LR_OS_SMOTE_Model_Predictions$Class <- as.factor(LR_OS_SMOTE_Model_Predictions$Class)
LR_OS_SMOTE_Model_Predictions$Label <- rep("LR_OS_SMOTE",nrow(LR_OS_SMOTE_Model_Predictions))

##################################
# Formulating the probability curve
# using the consolidated model predictions
##################################
LR_OS_SMOTE_Model_Predictions %>%
  ggplot(aes(x = LR_OS_SMOTE_LP ,
             y = LR_OS_SMOTE_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  ggtitle("Estimated Rock Detection Probabilities Based on Classification Index : Logistic Regression (OS_SMOTE)") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

```

</details>

###  1.5.9 Oversampling - Random Oversampling Examples  (LR_OS_ROSE)
|
| [Random Oversampling Examples](https://link.springer.com/article/10.1007/s10618-012-0295-5) generates synthetic data by enlarging the feature space of minority and majority class instances. The algorithm draws new examples from a conditional kernel density estimate of the two classes. The kernel is a normal product function centered at each of the instances with diagonal covariance matrix defined with the width of the neighborhood which is the asymptotically optimal smoothing matrix under the assumption of multivariate normality. 
|
| [Logistic Regression](http://dx.doi.org/10.2139/ssrn.360300) models the relationship between the probability of an event (among two outcome levels) by having the log-odds of the event be a linear combination of a set of predictors weighted by their respective parameter estimates. The parameters are estimated via maximum likelihood estimation by testing different values through multiple iterations to optimize for the best fit of log odds. All of these iterations produce the log likelihood function, and logistic regression seeks to maximize this function to find the best parameter estimates. Given the optimal parameters, the conditional probabilities for each observation can be calculated, logged, and summed together to yield a predicted probability.
|
| **[A]** The class ratio of the original data was noted at 80:20.
|      **[A.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 111 instances
|      **[A.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 25 instances
|
| **[B]** The class ratio of the oversampled data was noted at 50:50 with majority of the added instances being unique values for the minority class.
|      **[B.1]** Majority Class = <span style="color: #FF0000">Class=M</span> with 110 instances
|      **[B.2]** Minority Class = <span style="color: #FF0000">Class=R</span> with 112 instances
|
| **[C]** The logistic regression model from the <mark style="background-color: #CCECFF">**stats**</mark> package was implemented. The <span style="color: #FF0000">Class</span> response was regressed against the <span style="color: #FF0000">V1</span> and <span style="color: #FF0000">V11</span> predictors.
|
| **[D]** The logistic curve formulated by plotting the predicted probabilities against the classification index using the logit values showed a sufficiently balanced logistic profile for the predicted points from both the majority and minority classes. Although the ratio of the unique values and number of instances was relatively high, a significant overlap between both classes was observed.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.9, warning=FALSE, message=FALSE}
##################################
# Visualizing the imbalanced data set
##################################
ggplot(PMA_PreModelling_Train, aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "Without Oversampling - Random Oversampling Examples") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

##################################
# Implementing OS_ROSE
# Visualizing the oversampled data using OS_ROSE
##################################
recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_rose(Class, seed=123456789) %>%
  prep() %>%
  bake(new_data = NULL) %>%
  ggplot(aes(V1, V11, color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  labs(title = "With Oversampling - Random Oversampling Examples") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

OS_ROSE <- recipe(Class ~ V1 + V11, data = PMA_PreModelling_Train) %>%
  step_rose(Class, seed=123456789) %>%
  prep()

PMA_PreModelling_Train_LR_OS_ROSE <- OS_ROSE %>%
bake(new_data = NULL)

(PMA_PreModelling_Train_LR_OS_ROSE <- as.data.frame(PMA_PreModelling_Train_LR_OS_ROSE))
PMA_PreModelling_Train_LR_OS_ROSE$Label <- rep("LR_OS_ROSE",nrow(PMA_PreModelling_Train_LR_OS_ROSE))

##################################
# Verifying the class distribution
# for the oversampled data using OS_ROSE
##################################
table(PMA_PreModelling_Train_LR_OS_ROSE$Class) 

##################################
# Formulating the structure of the
# Logistic Regression model
##################################
LR_OS_ROSE_Model <- glm(Class ~ V1 + V11,
                data = PMA_PreModelling_Train_LR_OS_ROSE,
                family = binomial)

##################################
# Consolidating the model results
##################################
summary(LR_OS_ROSE_Model)

LR_OS_ROSE_Model_Coef <- (as.data.frame(LR_OS_ROSE_Model$coefficients))
LR_OS_ROSE_Model_Coef$Coef <- rownames(LR_OS_ROSE_Model_Coef)
LR_OS_ROSE_Model_Coef$Model <- rep("LR_OS_ROSE",nrow(LR_OS_ROSE_Model_Coef))
colnames(LR_OS_ROSE_Model_Coef) <- c("Estimates","Coefficients","Model")
print(LR_OS_ROSE_Model_Coef, rownames=FALSE)

##################################
# Computing the model predictions
##################################
(LR_OS_ROSE_Model_Probabilities <- predict(LR_OS_ROSE_Model, 
                              type = c("response")))

##################################
# Creating a classification index
# based from the model predictions
##################################
(LR_OS_ROSE_Model_Indices <- predict(LR_OS_ROSE_Model, 
                           type = c("link")))
max(LR_OS_ROSE_Model_Indices)
min(LR_OS_ROSE_Model_Indices)

##################################
# Consolidating the model probabilities
# and classification index
# based from the model predictions
##################################
LR_OS_ROSE_Model_Predictions <- as.data.frame(PMA_PreModelling_Train_LR_OS_ROSE)
LR_OS_ROSE_Model_Predictions$LR_OS_ROSE_Prob <- LR_OS_ROSE_Model_Probabilities
LR_OS_ROSE_Model_Predictions$LR_OS_ROSE_LP <- LR_OS_ROSE_Model_Indices
LR_OS_ROSE_Model_Predictions$Class <- as.factor(LR_OS_ROSE_Model_Predictions$Class)
LR_OS_ROSE_Model_Predictions$Label <- rep("LR_OS_ROSE",nrow(LR_OS_ROSE_Model_Predictions))

##################################
# Formulating the probability curve
# using the consolidated model predictions
##################################
LR_OS_ROSE_Model_Predictions %>%
  ggplot(aes(x = LR_OS_ROSE_LP ,
             y = LR_OS_ROSE_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  ggtitle("Estimated Rock Detection Probabilities Based on Classification Index : Logistic Regression (OS_ROSE)") +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

```

</details>

## 1.6 Evaluation Summary
|
| Undersampling and oversampling algorithm comparison:
|
| **[A]** The option to apply either an undersampling and oversampling method to augment imbalanced data prior to model training is predominantly driven by the quality and characteristics of the data set at hand. For large-sized data sets, undersampling methods may still prove effective in achieving balanced class distributions while maintaining a sufficient number of instances and reasonable computation complexity. For small- to medium-sized data sets, oversampling methods may help to maximize data augmentation while avoiding data sparsity in the resulting data update. The effectiveness of certain algorithms may vary depending on how discriminative the predictors are in distinguishing between classes.
| **[B]** Using the logistic regression model, the algorithm which demonstrated relatively better performance among other undersampling methods is the following:
|      **[B.1]** **LR_US_NEARMISS: Undersampling - Near Miss Algorithm**
|             **[B.1.1]** A sufficiently balanced logistic profile for the predicted points from both the majority and minority classes was achieved.
|             **[B.1.2]** As an undersampling method applied on a relatively small-sized original data set, the distribution of instances was relatively sparse.
| **[C]** Using the logistic regression model, the algorithm which demonstrated relatively better performance among other oversampling methods is the following:
|      **[C.1]** **LR_OS_BSMOTE: Oversampling - Borderline Synthetic Minority Oversampling Technique**
|             **[C.1.1]** A sufficiently balanced logistic profile for the predicted points from both the majority and minority classes was achieved.
|             **[C.1.2]** Minimal overlap between both classes was obtained although a minimal skew was still observed due to a longer tail for the predicted points belonging to the majority class.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.6, warning=FALSE, message=FALSE}
##################################
# Visualizing the imbalanced data set
# Visualizing the undersampled and oversampled data
##################################
LR_ClassDistribution <- PMA_PreModelling_Train_LR %>%
  ggplot(aes(x = V1 ,
             y = V11,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  theme_bw() +
  facet_grid(. ~ Label) +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=10, face="bold"),
        axis.title.y = element_text(color="black", size=10, face="bold"),
        legend.position="top")

LR_US_DOWNSAMPLE_ClassDistribution <- PMA_PreModelling_Train_LR_US_DOWNSAMPLE %>%  
  ggplot(aes(x = V1, 
             y = V11, 
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  theme_bw() +
  facet_grid(. ~ Label) +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

LR_OS_UPSAMPLE_ClassDistribution <- PMA_PreModelling_Train_LR_OS_UPSAMPLE %>%  
  ggplot(aes(x = V1, 
             y = V11, 
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  theme_bw() +
  facet_grid(. ~ Label) +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

LR_US_NEARMISS_ClassDistribution <- PMA_PreModelling_Train_LR_US_NEARMISS %>%  
  ggplot(aes(x = V1, 
             y = V11, 
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  theme_bw() +
  facet_grid(. ~ Label) +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

LR_US_TOMEK_ClassDistribution <- PMA_PreModelling_Train_LR_US_TOMEK %>%  
  ggplot(aes(x = V1, 
             y = V11, 
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  theme_bw() +
  facet_grid(. ~ Label) +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

LR_OS_ADASYN_ClassDistribution <- PMA_PreModelling_Train_LR_OS_ADASYN %>%  
  ggplot(aes(x = V1, 
             y = V11, 
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  theme_bw() +
  facet_grid(. ~ Label) +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

LR_OS_BSMOTE_ClassDistribution <- PMA_PreModelling_Train_LR_OS_BSMOTE %>%  
  ggplot(aes(x = V1, 
             y = V11, 
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  theme_bw() +
  facet_grid(. ~ Label) +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

LR_OS_SMOTE_ClassDistribution <- PMA_PreModelling_Train_LR_OS_SMOTE %>%  
  ggplot(aes(x = V1, 
             y = V11, 
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  theme_bw() +
  facet_grid(. ~ Label) +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

LR_OS_ROSE_ClassDistribution <- PMA_PreModelling_Train_LR_OS_ROSE %>%  
  ggplot(aes(x = V1, 
             y = V11, 
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  scale_x_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  scale_y_continuous( limits=c(-4,4), breaks=seq(-4,4,by=1)) +
  theme_bw() +
  facet_grid(. ~ Label) +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        legend.position="top")

RDD_ClassDistribution <- ggarrange(LR_ClassDistribution,
                                   LR_US_DOWNSAMPLE_ClassDistribution,
                                   LR_OS_UPSAMPLE_ClassDistribution,
                                   LR_US_NEARMISS_ClassDistribution,
                                   LR_US_TOMEK_ClassDistribution,
                                   LR_OS_ADASYN_ClassDistribution,
                                   LR_OS_BSMOTE_ClassDistribution,
                                   LR_OS_SMOTE_ClassDistribution,
                                   LR_OS_ROSE_ClassDistribution,
                                   ncol=3, nrow=3)

annotate_figure(RDD_ClassDistribution,
                top = text_grob("Class Distribution",
                                color = "black",
                                face = "bold",
                                size = 14))

##################################
# Replotting the logistic curves
##################################
LR_LogisticCurvePlot <- LR_Model_Predictions %>%
  ggplot(aes(x = LR_LP ,
             y = LR_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  facet_grid(. ~ Label) +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=10, face="bold"),
        axis.title.y = element_text(color="black", size=10, face="bold"),
        legend.position="top")

LR_US_DOWNSAMPLE_LogisticCurvePlot <- LR_US_DOWNSAMPLE_Model_Predictions %>%
  ggplot(aes(x = LR_US_DOWNSAMPLE_LP ,
             y = LR_US_DOWNSAMPLE_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  facet_grid(. ~ Label) +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=10, face="bold"),
        axis.title.y = element_text(color="black", size=10, face="bold"),
        legend.position="top")

LR_OS_UPSAMPLE_LogisticCurvePlot <- LR_OS_UPSAMPLE_Model_Predictions %>%
  ggplot(aes(x = LR_OS_UPSAMPLE_LP ,
             y = LR_OS_UPSAMPLE_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  facet_grid(. ~ Label) +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=10, face="bold"),
        axis.title.y = element_text(color="black", size=10, face="bold"),
        legend.position="top")

LR_US_NEARMISS_LogisticCurvePlot <- LR_US_NEARMISS_Model_Predictions %>%
  ggplot(aes(x = LR_US_NEARMISS_LP ,
             y = LR_US_NEARMISS_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  facet_grid(. ~ Label) +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=10, face="bold"),
        axis.title.y = element_text(color="black", size=10, face="bold"),
        legend.position="top")

LR_US_TOMEK_LogisticCurvePlot <- LR_US_TOMEK_Model_Predictions %>%
  ggplot(aes(x = LR_US_TOMEK_LP ,
             y = LR_US_TOMEK_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  facet_grid(. ~ Label) +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=10, face="bold"),
        axis.title.y = element_text(color="black", size=10, face="bold"),
        legend.position="top")

LR_OS_ADASYN_LogisticCurvePlot <-  LR_OS_ADASYN_Model_Predictions %>%
  ggplot(aes(x = LR_OS_ADASYN_LP ,
             y = LR_OS_ADASYN_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  facet_grid(. ~ Label) +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=10, face="bold"),
        axis.title.y = element_text(color="black", size=10, face="bold"),
        legend.position="top")

LR_OS_BSMOTE_LogisticCurvePlot <-  LR_OS_BSMOTE_Model_Predictions %>%
  ggplot(aes(x = LR_OS_BSMOTE_LP ,
             y = LR_OS_BSMOTE_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  facet_grid(. ~ Label) +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=10, face="bold"),
        axis.title.y = element_text(color="black", size=10, face="bold"),
        legend.position="top")

LR_OS_SMOTE_LogisticCurvePlot <-  LR_OS_SMOTE_Model_Predictions %>%
  ggplot(aes(x = LR_OS_SMOTE_LP ,
             y = LR_OS_SMOTE_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  facet_grid(. ~ Label) +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=10, face="bold"),
        axis.title.y = element_text(color="black", size=10, face="bold"),
        legend.position="top")

LR_OS_ROSE_LogisticCurvePlot <-  LR_OS_ROSE_Model_Predictions %>%
  ggplot(aes(x = LR_OS_ROSE_LP ,
             y = LR_OS_ROSE_Prob,
             color = Class)) +
  scale_colour_manual(values=c("#1846BA55","#B8000055")) +
  geom_point(size=5) +
  geom_line(color="black") +
  xlab("Sonar Object Classification Index (Logit Values)") +
  ylab("Estimated Rock Detection Probability") +
  labs(color = "Class") +
  scale_x_continuous( limits=c(-10,5), breaks=seq(-10,5,by=1)) +
  scale_y_continuous( limits=c(0,1), breaks=seq(0,1,by=0.1),labels = scales::percent) +
  facet_grid(. ~ Label) +
  theme_bw() +
  theme(plot.title = element_text(color="black", size=14, face="bold", hjust=0.50),
        axis.title.x = element_text(color="black", size=10, face="bold"),
        axis.title.y = element_text(color="black", size=10, face="bold"),
        legend.position="top")

RLR_LogisticCurvePlot <- ggarrange(LR_LogisticCurvePlot,
                                   LR_US_DOWNSAMPLE_LogisticCurvePlot,
                                   LR_OS_UPSAMPLE_LogisticCurvePlot,
                                   LR_US_NEARMISS_LogisticCurvePlot,
                                   LR_US_TOMEK_LogisticCurvePlot,
                                   LR_OS_ADASYN_LogisticCurvePlot,
                                   LR_OS_BSMOTE_LogisticCurvePlot,
                                   LR_OS_SMOTE_LogisticCurvePlot,
                                   LR_OS_ROSE_LogisticCurvePlot,
                                   ncol=3, nrow=3)

annotate_figure(RLR_LogisticCurvePlot,
                top = text_grob("Estimated Rock Detection Probabilities Based on Classification Index", 
                                color = "black", 
                                face = "bold", 
                                size = 14))

```

</details>

# **2. References**
|
| **[Book]** [Applied Predictive Modeling](http://appliedpredictivemodeling.com/) by Max Kuhn and Kjell Johnson
| **[Book]** [An Introduction to Statistical Learning](https://www.statlearning.com/) by Gareth James, Daniela Witten, Trevor Hastie and Rob Tibshirani
| **[Book]** [Multivariate Data Visualization with R](http://lmdvr.r-forge.r-project.org/figures/figures.html) by Deepayan Sarkar
| **[Book]** [Machine Learning](https://bookdown.org/ssjackson300/Machine-Learning-Lecture-Notes/) by Samuel Jackson
| **[Book]** [Data Modeling Methods](https://bookdown.org/larget_jacob/data-modeling-methods/) by Jacob Larget
| **[R Package]** [AppliedPredictiveModeling](https://cran.r-project.org/web//packages/AppliedPredictiveModeling/AppliedPredictiveModeling.pdf) by Max Kuhn
| **[R Package]** [caret](https://topepo.github.io/caret/index.html) by Max Kuhn
| **[R Package]** [rpart](https://mran.microsoft.com/web/packages/rpart/rpart.pdf) by Terry Therneau and Beth Atkinson
| **[R Package]** [lattice](https://cran.r-project.org/web/packages/lattice/lattice.pdf) by  Deepayan Sarkar
| **[R Package]** [dplyr](https://cran.r-project.org/web/packages/dplyr/index.html/) by Hadley Wickham
| **[R Package]** [moments](https://cran.r-project.org/web/packages/moments/index.html) by Lukasz Komsta and Frederick
| **[R Package]** [skimr](https://cran.r-project.org/web/packages/skimr/skimr.pdf) by  Elin Waring
| **[R Package]** [RANN](https://cran.r-project.org/web/packages/RANN/RANN.pdf) by  Sunil Arya, David Mount, Samuel Kemp and Gregory Jefferis
| **[R Package]** [corrplot](https://cran.r-project.org/web/packages/corrplot/corrplot.pdf) by Taiyun Wei
| **[R Package]** [tidyverse](https://cran.r-project.org/web/packages/tidyverse/tidyverse.pdf) by Hadley Wickham
| **[R Package]** [lares](https://cran.rstudio.com/web/packages/lares/lares.pdf) by Bernardo Lares
| **[R Package]** [DMwR](https://mran.microsoft.com/snapshot/2016-05-02/web/packages/DMwR/DMwR.pdf) by Luis Torgo
| **[R Package]** [gridExtra](https://cran.r-project.org/web/packages/gridExtra/gridExtra.pdf) by Baptiste Auguie and Anton Antonov
| **[R Package]** [rattle](https://cran.r-project.org/web/packages/rattle/rattle.pdf) by Graham Williams
| **[R Package]** [rpart.plot](https://cran.r-project.org/web/packages/rpart.plot/rpart.plot.pdf) by Stephen Milborrow
| **[R Package]** [RColorBrewer](https://cran.r-project.org/web//packages/RColorBrewer/RColorBrewer.pdf) by Erich Neuwirth
| **[R Package]** [stats](https://search.r-project.org/R/refmans/stats/html/00Index.html) by R Core Team
| **[R Package]** [pls](https://cran.r-project.org/web/packages/pls/pls.pdf) by Kristian Hovde Liland
| **[R Package]** [nnet](https://cran.r-project.org/web/packages/nnet/nnet.pdf) by Brian Ripley
| **[R Package]** [elasticnet](https://cran.r-project.org/web/packages/elasticnet/elasticnet.pdf) by Hui Zou
| **[R Package]** [earth](https://cran.r-project.org/web/packages/earth/earth.pdf) by Stephen Milborrow
| **[R Package]** [party](https://cran.r-project.org/web/packages/party/party.pdf) by Torsten Hothorn
| **[R Package]** [kernlab](https://cran.r-project.org/web/packages/kernlab/kernlab.pdf) by Alexandros Karatzoglou
| **[R Package]** [randomForest](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf) by Andy Liaw
| **[R Package]** [pROC](https://cran.r-project.org/web/packages/pROC/pROC.pdf) by Xavier Robin
| **[R Package]** [mda](https://cran.r-project.org/web/packages/mda/mda.pdf) by Trevor Hastie
| **[R Package]** [klaR](https://cran.r-project.org/web/packages/klaR/klaR.pdf) by Christian Roever, Nils Raabe, Karsten Luebke, Uwe Ligges, Gero Szepannek, Marc Zentgraf and David Meyer
| **[R Package]** [pamr](https://cran.r-project.org/web/packages/pamr/pamr.pdf) by Trevor Hastie, Rob Tibshirani, Balasubramanian Narasimhan and Gil Chu
| **[R Package]** [ROSE](https://cran.r-project.org/web/packages/ROSE/ROSE.pdf) by Nicola Lunardon
| **[R Package]** [themis](https://cran.r-project.org/web/packages/themis/themis.pdf) by Emil Hvitfeldt
| **[Article]** [The caret Package](https://topepo.github.io/caret/index.html) by Max Kuhn
| **[Article]** [A Short Introduction to the caret Package](https://cran.r-project.org/web/packages/caret/vignettes/caret.html) by Max Kuhn
| **[Article]** [Caret Package â€“ A Practical Guide to Machine Learning in R](https://www.machinelearningplus.com/machine-learning/caret-package/#:~:text=Caret%20is%20short%20for%20Classification%20And%20REgression%20Training.,track%20of%20which%20algorithm%20resides%20in%20which%20package.) by Selva Prabhakaran
| **[Article]** [Tuning Machine Learning Models Using the Caret R Package](https://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/) by Jason Brownlee
| **[Article]** [Lattice Graphs](http://www.sthda.com/english/wiki/lattice-graphs) by Alboukadel Kassambara
| **[Article]** [A Tour of Machine Learning Algorithms](https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/) by Jason Brownlee
| **[Article]** [Decision Tree Algorithm Examples In Data Mining](https://www.softwaretestinghelp.com/decision-tree-algorithm-examples-data-mining/) by Software Testing Help Team
| **[Article]** [4 Types of Classification Tasks in Machine Learning](https://machinelearningmastery.com/types-of-classification-in-machine-learning/) by Jason Brownlee
| **[Article]** [Spot-Check Classification Machine Learning Algorithms in Python with scikit-learn](https://machinelearningmastery.com/spot-check-classification-machine-learning-algorithms-python-scikit-learn/) by Jason Brownlee
| **[Article]** [Feature Engineering and Selection: A Practical Approach for Predictive Models](http://www.feat.engineering/index.html) by Max Kuhn and Kjell Johnson
| **[Article]** [Machine Learning Tutorial: A Step-by-Step Guide for Beginners](http://www.feat.engineering/index.html) by Mayank Banoula
| **[Article]** [Classification Tree](https://support.bccvl.org.au/support/solutions/articles/6000083204-classification-tree) by BCCVL Team
| **[Article]** [A Gentle Introduction to Imbalanced Classification](https://machinelearningmastery.com/what-is-imbalanced-classification/) by Jason Brownlee
| **[Article]** [8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/#:~:text=8%20Tactics%20To%20Combat%20Imbalanced%20Training%20Data%201,Different%20Perspective%20...%208%208%29%20Try%20Getting%20Creative) by Jason Brownlee
| **[Article]** [Step-By-Step Framework for Imbalanced Classification Projects](https://machinelearningmastery.com/framework-for-imbalanced-classification-projects/) by Jason Brownlee
| **[Article]** [How to Handle Imbalanced Classes in Machine Learning](https://elitedatascience.com/imbalanced-classes) by Elite Data Science Team
| **[Article]** [Best Ways To Handle Imbalanced Data in Machine Learning](https://dataaspirant.com/handle-imbalanced-data-machine-learning/) by Jaiganesh Nagidi
| **[Article]** [Handling Imbalanced Data for Classification](https://www.geeksforgeeks.org/handling-imbalanced-data-for-classification/) by Geeks For Geeks Team
| **[Article]** [Random Oversampling and Undersampling for Imbalanced Classification](https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/#:~:text=Random%20undersampling%20involves%20randomly%20selecting%20examples%20from%20the,45%2C%20Imbalanced%20Learning%3A%20Foundations%2C%20Algorithms%2C%20and%20Applications%2C%202013) by Jason Brownlee
| **[Publication]** [The Origins of Logistic Regression](http://dx.doi.org/10.2139/ssrn.360300) by JS Cramer (Econometrics eJournal)
| **[Publication]** [KNN Approach to Unbalanced Data Distributions: A Case Study Involving Information Extraction](https://www.academia.edu/12815658/knn_approach_to_unbalanced_data_distributions_A_case_study_involving_information_extraction) by Inderjeet Mani and J Zhang (Proceedings of Workshop on Learning from Imbalanced Datasets)
| **[Publication]** [Two Modifications of CNN](https://ieeexplore.ieee.org/document/4309452) by Ivan Tomek (IEEE Transactions on Systems, Man, and Cybernetics)
| **[Publication]** [ADASYN: Adaptive Synthetic Sampling Approach for Imbalanced Learning](https://ieeexplore.ieee.org/document/4633969) by Haibo He, Yang Bai, Edwardo Garcia and Shutao Li (IEEE World Congress on Computational Intelligence)
| **[Publication]** [Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning](https://link.springer.com/chapter/10.1007/11538059_91) by Hui Han, Wenyuan Wang and Binghuan Mao (International Conference on Intelligent Computing)
| **[Publication]** [SMOTE: Synthetic Minority Over-Sampling Technique](https://dl.acm.org/doi/10.5555/1622407.1622416) by Nitesh Chawla, Kevin Bowyer, Lawrence Hall and Philip Kegelmeyer (Journal of Artificial Intelligence Research)
| **[Publication]** [Training and Assessing Classification Rules with Imbalanced Data](https://link.springer.com/article/10.1007/s10618-012-0295-5) by Giovanna Menardi and Nicola Torelli (Data Mining and Knowledge Discovery)
| **[Publication]** [A Study of the Behavior of Several Methods for Balancing Machine Learning Training Data](https://dl.acm.org/doi/10.1145/1007730.1007735) by Gustavo Batista, Ronaldo Prati and Maria Carolina Monard (ACM SIGKDD Explorations Newsletter)
| **[Publication]** [A Survey of Predictive Modelling under Imbalanced Distributiona](https://arxiv.org/abs/1505.01658) by Paula Branco, Luis Torgo and Rita Ribeiro (Arxiv Cornell University)
| **[Course]** [Applied Data Mining and Statistical Learning](https://online.stat.psu.edu/stat508/) by Penn State Eberly College of Science
| **[Course]** [Regression Methods](https://online.stat.psu.edu/stat501/) by Penn State Eberly College of Science
| **[Course]** [Applied Regression Analysis](https://online.stat.psu.edu/stat462/) by Penn State Eberly College of Science
| **[Course]** [Applied Data Mining and Statistical Learning](https://online.stat.psu.edu/stat508/) by Penn State Eberly College of Science
|
|
|
|